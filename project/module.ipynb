{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "notes:\n",
    "\n",
    "- in sampling, we initialize z to be all ones. maybe we should do all zeros?\n",
    "\n",
    "  actually i dont think it matters, the overwhelming quantity of data points makes the posterior disregard completely such hyperparameters and initializations.\n",
    "\n",
    "- amazingly, by adding noise to the data the algorithm works better, but still the masking vectors are all 1. \n",
    "  how can we mke the algorithm more prone to setting some variables to zero instead of just sampling near zero from a gaussian?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will try to explore the `PySINDy` package architecture, in order to easily implement our bayesian version of this algorithm with a sparsity inducing prior.\n",
    "\n",
    "We will implement a \"custom\" `optimizer` module, that will implement a Maximum A Posteriori (_MAP_) algorithm over the distribution derived from data and a (possibly sparsity-inducing) prior distribution.\n",
    "The main difference is that this object will retain information over the whole probability distribution for the coefficients $\\boldsymbol{\\xi}$ and not just the best estimates, so that we can evaluate uncertainties over such parameters.\n",
    "\n",
    "The goal of this algorithm is to compute\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\xi}|\\boldsymbol{\\dot{u}},\\boldsymbol{\\Theta}) = P(\\boldsymbol{\\dot{u}}|\\boldsymbol{\\xi},\\boldsymbol{\\Theta})P(\\boldsymbol{\\xi})\n",
    "$$\n",
    "\n",
    "Under the assumption that the likelihood of observing $\\boldsymbol{\\dot{u}}$ given a certain coefficients vector $\\boldsymbol{\\xi}$ is a gaussian with mean given by the linear relation:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\dot{u}}|\\boldsymbol{\\xi},\\boldsymbol{\\Theta}) \\sim \\mathcal{N}(\\boldsymbol{\\Theta}^T\\boldsymbol{\\xi},\\sigma^2)\n",
    "$$\n",
    "\n",
    "\n",
    "And $P(\\boldsymbol{\\xi})$ will be a sparsity inducing prior, so that the original goal of finding the smallest amount of explanatory terms possible is somewhat obtained.\n",
    "\n",
    "### Spike and Slab regression\n",
    "\n",
    "The spike and slab regression is considered to be the golden standard of sparsity inducing priors. The main idea behind it is to build prior that's a \"mixture\" of some smooth other \"slab\" prior (such as some ridge regression gaussian pit) and a delta function (the spike), centered at some point $v$; a latent random variable $Z \\sim Ber(\\theta_i)$ decides which prior to use:\n",
    "\n",
    "$$\n",
    "P(\\xi_i | z_i) = 0 \\sim \\delta(\\xi_i-v) \\\\\n",
    "P(\\xi_i | z_i) = 1 \\sim P_{slab}(\\xi_i) \n",
    "$$\n",
    "\n",
    "So that the prior is the slab function with probability $\\theta_i$ or collapses at $v$ with probability $1-\\theta_i$. Setting $v=0$ corresponds to the sparsity assumption. If we marginalize over $z_i$:\n",
    "\n",
    "$$\n",
    "P(\\xi_i) = \\sum_{z_i=0}^1 P(\\xi_i|z_i)P(z_i) = \\theta_i P_{slab}(\\xi_i) + (1-\\theta_i)\\delta(\\xi_i)\n",
    "$$\n",
    "\n",
    "If we denote with $\\circ$ the Hadamard product (element-wise product), we can express the likelihood of the data given a certain \"masking vector\" $\\boldsymbol{z}$ and a coefficients vector $\\boldsymbol{\\xi}$ as\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\dot{u}}|\\boldsymbol{\\xi},\\boldsymbol{z},\\boldsymbol{\\Theta},\\sigma^2) \\sim \\mathcal{N}(<\\boldsymbol{z}\\circ \\boldsymbol{\\xi},\\Theta>,\\sigma^2)\n",
    "$$\n",
    "\n",
    "And thus, if we simply denote the data as $\\mathcal{D}$, we have the posterior\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{z},\\boldsymbol{\\xi}|\\mathcal{D}) = \\frac{1}{P(\\mathcal{D})} P(\\boldsymbol{z}) P_{slab}(\\boldsymbol{\\xi})\\prod_{\\mathcal{D}}P(\\boldsymbol{\\dot{u}}|\\boldsymbol{\\xi},\\boldsymbol{z},\\boldsymbol{\\Theta},\\sigma^2)\n",
    "$$\n",
    "\n",
    "The evidence would need to be computed by integrating over all (infinitely many) possible values of $\\boldsymbol{\\xi}$ and the all the possible ($2^N$) combinations for $\\boldsymbol{z}$; it is clear that an analytical derivation of this posterior distribution is infeasible and a sampling approach will need to be deployed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `BaseOptimizer` class\n",
    "\n",
    "This is the wrapper class for each optimizer algorithm that the package provides; we will build a optimizer module as a subclass of this wrapper. <a href=https://pysindy.readthedocs.io/en/latest/_modules/pysindy/optimizers/base.html#BaseOptimizer>Source code</a> is available on the documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysindy.optimizers import BaseOptimizer\n",
    "import numpy as np\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.linear_model._base import _preprocess_data\n",
    "from scipy.stats import beta,gamma,multivariate_normal,binom,mode\n",
    "from alive_progress import alive_bar # package to print the pretty progress bar. can be installed with pip install alive-progress\n",
    "\n",
    "\n",
    "\n",
    "def _rescale_data(X, y, sample_weight):\n",
    "    \"\"\"Rescale data so as to support sample_weight\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    sample_weight = np.asarray(sample_weight)\n",
    "    if sample_weight.ndim == 0:\n",
    "        sample_weight = np.full(n_samples, sample_weight, dtype=sample_weight.dtype)\n",
    "    sample_weight = np.sqrt(sample_weight)\n",
    "    sw_matrix = sparse.dia_matrix((sample_weight, 0), shape=(n_samples, n_samples))\n",
    "    X = safe_sparse_dot(sw_matrix, X)\n",
    "    y = safe_sparse_dot(sw_matrix, y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class SpikeSlabRegression (BaseOptimizer):\n",
    "    \"\"\"\n",
    "    Bayesian Regression with a Spike and Slab type prior Optimizer.\n",
    "    \n",
    "    Computes the most likely combination of the coefficient vector\n",
    "    and the masking vector using Bayesian inference to compute the \n",
    "    posterior distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fit_intercept : boolean, optional (default False)\n",
    "        Whether to calculate the intercept for this model. If set to false, no\n",
    "        intercept will be used in calculations.\n",
    "\n",
    "    normalize_columns : boolean, optional (default False)\n",
    "        Normalize the columns of x (the SINDy library terms) before regression\n",
    "        by dividing by the L2-norm. Note that the 'normalize' option in sklearn\n",
    "        is deprecated in sklearn versions >= 1.0 and will be removed.\n",
    "\n",
    "    copy_X : boolean, optional (default True)\n",
    "        If True, X will be copied; else, it may be overwritten.\n",
    "    \n",
    "\n",
    "    max_iter : int, optional (default 5000)\n",
    "        Maximum iterations of the optimization algorithm, i.e. the length of the Gibbs sampling chain.\n",
    "\n",
    "    burn_in : int, optional (default 1500)\n",
    "        Number of samples from the sampling chain to discard.\n",
    "    \n",
    "    verbose : boolean, optional (default False)\n",
    "        enables verbose\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    coef_ : array, shape (n_features,) or (n_targets,n_features)\n",
    "        Coefficients vector.\n",
    "\n",
    "    ind_ : array, shape (n_features,) or (n_targets,n_features)\n",
    "        Vector of BOOL values indicating whether or not a feature is considered relevant in the sparse representation.\n",
    "\n",
    "    samples : list of length (n_targets) \n",
    "        Dictionaries containing np.arrays of the samples generated by the Gibbs sampling algorithm.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        max_iter=5000, \n",
    "        burn_in=1500,\n",
    "        normalize_columns=False, \n",
    "        fit_intercept=False, \n",
    "        initial_guess=None, \n",
    "        copy_X=True,\n",
    "        tol=1e-5, # apparently needed for compatibility?\n",
    "        alpha=None, # idk\n",
    "        verbose=False\n",
    "        ):\n",
    "\n",
    "        # super() calls a temporary version of the parent class\n",
    "        # this way we pass the init parameters to the class itself via inheritance\n",
    "        # without having to rewrite everything\n",
    "        super().__init__(max_iter, normalize_columns, fit_intercept, initial_guess, copy_X)\n",
    "\n",
    "        self.tol=tol\n",
    "        self.alpha=alpha\n",
    "        self.burn_in = burn_in\n",
    "        if self.max_iter <= 0:\n",
    "            raise ValueError(\"Max iteration must be > 0\")\n",
    "        self.verbose=verbose\n",
    "\n",
    "    # WE WILL OVERRIDE THE FIT METHOD FROM BaseEstimator SINCE WE WANT DIFFERENT .ind_ attributes\n",
    "\n",
    "    def fit(self, x_, y, sample_weight=None, **reduce_kws):\n",
    "        \"\"\"\n",
    "        Fit the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_ : array-like, shape (n_samples, n_features)\n",
    "            Training data\n",
    "\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_targets)\n",
    "            Target values\n",
    "\n",
    "        sample_weight : float or numpy array of shape (n_samples,), optional\n",
    "            Individual weights for each sample\n",
    "\n",
    "        reduce_kws : dict\n",
    "            Optional keyword arguments to pass to the _reduce method\n",
    "            (implemented by subclasses)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self\n",
    "        \"\"\"\n",
    "\n",
    "        # ----------- rescaling part\n",
    "        x_, y = check_X_y(x_, y, accept_sparse=[], y_numeric=True, multi_output=True)\n",
    "\n",
    "        x, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
    "            x_,\n",
    "            y,\n",
    "            fit_intercept=self.fit_intercept,\n",
    "            copy=self.copy_X,\n",
    "            sample_weight=sample_weight,\n",
    "        )\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            x, y = _rescale_data(x, y, sample_weight)\n",
    "\n",
    "        self.iters = 0\n",
    "\n",
    "\n",
    "        # ------------ preparing dimensions, if there is only one target (only one time derivative) then we set it (-1,1) shape\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        coef_shape = (y.shape[1], x.shape[1])\n",
    "        self.ind_ = np.ones(coef_shape, dtype=bool)\n",
    "\n",
    "        # ----------- normalization\n",
    "        self.Theta_ = x # saving original theta\n",
    "        x_normed = np.copy(x)\n",
    "        if self.normalize_columns:\n",
    "            reg = 1 / np.linalg.norm(x, 2, axis=0)\n",
    "            x_normed = x * reg\n",
    "\n",
    "        # ---------------------------------------------DO WE NEED THIS? NOT REALLY\n",
    "        # ----------- initial guess via ols\n",
    "        # if self.initial_guess is None:\n",
    "        #     self.coef_ = np.linalg.lstsq(x_normed, y, rcond=None)[0].T\n",
    "        # else:\n",
    "        #     if not self.initial_guess.shape == coef_shape:\n",
    "        #         raise ValueError(\n",
    "        #             \"initial_guess shape is incompatible with training data. \"\n",
    "        #             f\"Expected: {coef_shape}. Received: {self.initial_guess.shape}.\"\n",
    "        #         )\n",
    "        #     self.coef_ = self.initial_guess\n",
    "\n",
    "\n",
    "        # ---------------???\n",
    "        # self.history_ = [self.coef_]\n",
    "\n",
    "\n",
    "\n",
    "        # WHERE THE MAGIC HAPPENS\n",
    "\n",
    "        self._reduce(x_normed, y, **reduce_kws)\n",
    "        #self.ind_ = np.abs(self.coef_) > 1e-14 # WE WILL SET THIS IN THE REDUCE METHOD, its gonna be the most probable z vector\n",
    "\n",
    "        # Rescale coefficients to original units\n",
    "        if self.normalize_columns:\n",
    "            self.coef_ = np.multiply(reg, self.coef_)\n",
    "            if hasattr(self, \"coef_full_\"):\n",
    "                self.coef_full_ = np.multiply(reg, self.coef_full_)\n",
    "            for i in range(np.shape(self.history_)[0]):\n",
    "                self.history_[i] = np.multiply(reg, self.history_[i])\n",
    "\n",
    "        self._set_intercept(X_offset, y_offset, X_scale)\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def sampling(self,y,X,a1=0.01,a2=0.01,theta=0.5,a=1.,b=10.,s=0.5):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # dictionary of empty arrays to store different samples\n",
    "        res = {\n",
    "            \"beta\" : np.empty((self.max_iter,n_features)),\n",
    "            \"z\" : np.empty((self.max_iter,n_features)),\n",
    "            \"sigma2\" : np.empty(self.max_iter),\n",
    "            \"tau2\" : np.empty(self.max_iter),\n",
    "            \"theta\" : np.empty(self.max_iter)\n",
    "        }\n",
    "\n",
    "        # initialize the masking as ones\n",
    "        # OR ZEROS????\n",
    "        res[\"z\"][0] = np.zeros(n_features)\n",
    "        # initialize the beta as least square regression\n",
    "        res[\"beta\"][0] = np.linalg.lstsq(X,y,rcond=None)[0]\n",
    "        # initialize the sigma as the variance of the residuals\n",
    "        res[\"sigma2\"][0] = np.var(y - X @ res[\"beta\"][0])\n",
    "        # initialize the tau2 as one and the theta as 0.5\n",
    "        res[\"tau2\"][0] = 1.\n",
    "        res[\"theta\"][0] = 0.5\n",
    "\n",
    "        # compute only once\n",
    "        XtX = X.T @ X\n",
    "        Xty = X.T @ y\n",
    "\n",
    "        # ----------------- BEGIN SAMPLING\n",
    "        with alive_bar(self.max_iter-1,force_tty=True) as bar:\n",
    "\n",
    "            for i in range(1,self.max_iter):\n",
    "\n",
    "\n",
    "                # lets retrieve the previous values for easier coding\n",
    "                z_prev = res[\"z\"][i-1]\n",
    "                beta_prev = res[\"beta\"][i-1]\n",
    "                sigma2_prev = res[\"sigma2\"][i-1]\n",
    "                tau2_prev = res[\"tau2\"][i-1]\n",
    "                theta_prev = res[\"theta\"][i-1]\n",
    "\n",
    "                # ------------------ LETS GO WITH THE CONDITIONALS\n",
    "\n",
    "                # sample theta from a Beta distribution\n",
    "                theta_new = beta.rvs(a + np.sum(z_prev),b+np.sum(1-z_prev))\n",
    "\n",
    "                # sample sigma2 from an inverse gamma\n",
    "                err = y - X @ beta_prev\n",
    "                scale = 1./(a2 + (err.T @ err)/2)\n",
    "                sigma2_new = 1./gamma.rvs(a1+n_samples/2,scale=scale)\n",
    "\n",
    "                # sample tau2 from an inverse gamma\n",
    "                scale = 1./((s**2)/2 + (beta_prev.T @ beta_prev)/(2*sigma2_new))\n",
    "                tau2_new = 1./gamma.rvs(0.5+0.5*np.sum(z_prev),scale=scale)\n",
    "\n",
    "                # sample new beta from a multivariate gaussian\n",
    "                covariance = np.linalg.inv(XtX/sigma2_new + np.eye(n_features)/(sigma2_new*tau2_new))\n",
    "                mean = covariance @ Xty /sigma2_new # is this right?\n",
    "                beta_new = multivariate_normal.rvs(mean = mean,cov=covariance)\n",
    "\n",
    "                # now we sample the zjs\n",
    "                # in random order\n",
    "                for j in np.random.permutation(n_features):\n",
    "                    \n",
    "                    # grab the current vector\n",
    "                    z0 = z_prev\n",
    "                    # set j to zero\n",
    "                    z0[j] = 0.\n",
    "                    # get the beta_{-j}\n",
    "                    bz0 = beta_new * z0\n",
    "\n",
    "                    # compute the u variables (one for each sample)\n",
    "                    xj = X[:,j] # the jth feature of each sample\n",
    "                    u = y - X @ bz0 \n",
    "                    cond_var = np.sum(xj**2) + 1./tau2_new\n",
    "\n",
    "                    # compute the chance parameter:\n",
    "                    # the probability of extracting zj = 0 is prop to (1-theta)\n",
    "                    # while of extracting zj=1 is (.....) mess \n",
    "                    # computing the logarithm of these (l0 and l1) means that the probability of extracting zj=1 is\n",
    "                    # xi = exp(l1)/(exp(l1)+exp(l0))\n",
    "                    # we can also write this as\n",
    "                    # xi = 1/(1+ exp(l0-l1))\n",
    "                    # this way we can check if exp(l0-l1) overflows and just call it xi = 0\n",
    "\n",
    "                    l0 = np.log(1-theta_new)\n",
    "                    l1 = np.log(theta_new) \\\n",
    "                        - 0.5 * np.log(tau2_new*sigma2_new) \\\n",
    "                        + (np.sum(xj*u)**2)/(2*sigma2_new*cond_var) \\\n",
    "                        + 0.5*np.log(sigma2_new/cond_var)\n",
    "\n",
    "                    el0_l1 = np.exp(l0-l1)\n",
    "                    if np.isinf(el0_l1):\n",
    "                        xi = 0\n",
    "                    else:\n",
    "                        xi = 1/(1+el0_l1)\n",
    "                    \n",
    "                    # extract the zj\n",
    "                    z_prev[j]=binom.rvs(1,xi)\n",
    "\n",
    "                # once we extracted all zj, store them:\n",
    "                z_new = z_prev\n",
    "\n",
    "                # update everything\n",
    "\n",
    "                res[\"z\"][i] = z_new\n",
    "                # res[\"beta\"][i] = beta_new\n",
    "                res[\"beta\"][i] = beta_new*z_new\n",
    "                res[\"sigma2\"][i] = sigma2_new\n",
    "                res[\"tau2\"][i] = tau2_new\n",
    "                res[\"theta\"][i] = theta_new\n",
    "\n",
    "                if self.verbose:\n",
    "                    bar()\n",
    "\n",
    "            # ---------- END SAMPLING\n",
    "\n",
    "        for k in res.keys():\n",
    "            res[k] = res[k][self.burn_in:]\n",
    "        \n",
    "        return res \n",
    "\n",
    "\n",
    "    def _reduce(self,x,y,**sampling_kws):\n",
    "        \"\"\"\n",
    "        Reduce method to actually perform the minimization.\n",
    "        This method performs a Gibbs sampling of the joint probability distribution\n",
    "        Under the spike and slab prior method, and will return the coefficients\n",
    "        as the most probable one, given the most probable masking coefficient.\n",
    "        \"\"\"\n",
    "\n",
    "        n_samples, n_features = x.shape\n",
    "        # what if there are multiple targets? i.e. a 3d dynamical system?\n",
    "        n_targets = y.shape[1]\n",
    "        # then we need to perform the regression and find (n_targets) vector of coefficients.\n",
    "        # so the coefficient will be\n",
    "        coef = np.zeros((n_targets,n_features))\n",
    "        ind = np.zeros((n_targets,n_features))\n",
    "        self.samples = []\n",
    "\n",
    "        for i in range(n_targets):\n",
    "\n",
    "            if self.verbose: \n",
    "                print(\"Sampling for feature n# {}/{}...\".format(i,n_targets-1))\n",
    "            \n",
    "            # KERNEL DENSITY ESTIMATE HERE MAYBE?\n",
    "            # but for now only pick the mean\n",
    "\n",
    "            # we can call y[i] because it's been reshaped to (-1,1) even if n_targets=1\n",
    "            self.samples.append(self.sampling(y[:,i],x,**sampling_kws))\n",
    "            coef[i] = np.mean(self.samples[i]['beta'],axis=0)\n",
    "            ind[i] = mode(self.samples[i]['z']) != 0 # setting the .ind_ attribute as a boolean vector\n",
    "\n",
    "\n",
    "        self.coef_ = coef\n",
    "\n",
    "        self.ind_ = ind\n",
    "\n",
    "\n",
    "    def summary(self):\n",
    "\n",
    "        for target in range(len(self.samples)):\n",
    "            \n",
    "            print(\"------------------------\")\n",
    "            print(\"Target variable n# \",target)\n",
    "\n",
    "            beta_mean = np.mean(self.samples[target]['beta'],axis=0)\n",
    "            beta_std = np.std(self.samples[target]['beta'],axis=0)\n",
    "            print(\"Marginalized Beta distribution mean:\")\n",
    "            print(beta_mean)\n",
    "            print(\"Marginalized Beta distribution std:\")\n",
    "            print(beta_std)\n",
    "            \n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            z_mean = np.mean(self.samples[target]['z'],axis=0)\n",
    "            z_std = np.std(self.samples[target]['z'],axis=0)\n",
    "            print(\"Marginalized Z distribution mean:\")\n",
    "            print(z_mean)\n",
    "            print(\"Marginalized Z distribution std:\")\n",
    "            print(z_std)\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            tau2_mean = np.mean(self.samples[target]['tau2'])\n",
    "            tau2_std = np.std(self.samples[target]['tau2'])\n",
    "            print(\"Marginalized Tau2 distribution mean:\")\n",
    "            print(tau2_mean)\n",
    "            print(\"Marginalized Tau2 distribution std:\")\n",
    "            print(tau2_std)\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            sigma2_mean = np.mean(self.samples[target]['sigma2'])\n",
    "            sigma2_std = np.std(self.samples[target]['sigma2'])\n",
    "            print(\"Marginalized Sigma2 distribution mean:\")\n",
    "            print(sigma2_mean)\n",
    "            print(\"Marginalized Sigma2 distribution std:\")\n",
    "            print(sigma2_std)\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            theta_mean = np.mean(self.samples[target]['theta'])\n",
    "            theta_std = np.std(self.samples[target]['theta'])\n",
    "            print(\"Marginalized Theta distribution mean:\")\n",
    "            print(theta_mean)\n",
    "            print(\"Marginalized Theta distribution std:\")\n",
    "            print(theta_std)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data vector:\n",
      "[[1.         1.         1.        ]\n",
      " [1.01256821 1.2599461  0.98488969]\n",
      " [1.04883096 1.52405449 0.97311235]\n",
      " [1.10722704 1.79839899 0.96515735]\n",
      " [1.18690156 2.08866556 0.96173704]]\n",
      "\n",
      "\n",
      "Time vector:\n",
      "[0.       0.010001 0.020002 0.030003 0.040004]\n"
     ]
    }
   ],
   "source": [
    "import pysindy as ps\n",
    "\n",
    "# load data\n",
    "r_noisy = np.load(\"./data/lorenz_r_noisy.npy\")\n",
    "t = np.load(\"./data/lorenz_t.npy\")\n",
    "\n",
    "# r is shaped like (n_points,n_dimensions)\n",
    "print(\"Data vector:\")\n",
    "print(r_noisy[:5])\n",
    "\n",
    "# t is time axis\n",
    "print(\"\\n\\nTime vector:\")\n",
    "print(t[:5])\n",
    "\n",
    "feature_names = ['x','y','z'] # just a label for the features, instead of simply using x1,x2....\n",
    "\n",
    "opt=SpikeSlabRegression(max_iter=5000,burn_in=1500,verbose=True)\n",
    "\n",
    "model = ps.SINDy(feature_names=feature_names,optimizer=opt) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling for feature n# 0/2...\n",
      "|████████████████████████████████████████| 4999/4999 [100%] in 32.8s (152.61/s)                                         \n",
      "Sampling for feature n# 1/2...\n",
      "|████████████████████████████████████████| 4999/4999 [100%] in 46.8s (106.91/s)                                         \n",
      "Sampling for feature n# 2/2...\n",
      "|████████████████████████████████████████| 4999/4999 [100%] in 35.2s (142.16/s)                                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SINDy(differentiation_method=FiniteDifference(),\n",
       "      feature_library=PolynomialLibrary(), feature_names=['x', 'y', 'z'],\n",
       "      optimizer=SpikeSlabRegression(verbose=True))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .fit method from pysindy class does not have a **kwargs!\n",
    "model.fit(r_noisy,t=t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x)' = 0.003 1 + -10.056 x + 10.040 y + 0.002 x z + -0.002 y z\n",
      "(y)' = 0.029 1 + 27.799 x + -0.955 y + -0.003 z + -0.994 x z\n",
      "(z)' = -0.292 1 + -0.012 x + 0.008 y + -2.586 z + 0.025 x^2 + 0.973 x y + 0.006 y^2 + -0.003 z^2\n"
     ]
    }
   ],
   "source": [
    "model.print() # some of the coefficients may not show up even if their .ind_ is True; this is because\n",
    "              # the precision argument in .print() defaults to 3 decimal places and if they are all zeros\n",
    "              # the term isnt printed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lets look at the x' equation\n",
    "samp = model.optimizer.samples[0]\n",
    "feat = model.get_feature_names()\n",
    "\n",
    "fig, axs = plt.subplots(2,10,figsize=[20,5])\n",
    "colors=plt.get_cmap('tab20')\n",
    "fig.tight_layout()\n",
    "for i in range(10):\n",
    "    axs[0,i].hist(samp['beta'][:,i],color=colors.colors[2*i])\n",
    "    axs[0,i].set_title(\"Coef of {}\".format(feat[i]))\n",
    "    axs[1,i].hist(samp['z'][:,i],color=colors.colors[2*i+1])\n",
    "    axs[1,i].set_title(\"Masking of {}\".format(feat[i]))\n",
    "\n",
    "\n",
    "print(model.optimizer.ind_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b48686ecf5c051869e44bca573c1817bb1844fb32a5df209df0a7813f2e01a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
