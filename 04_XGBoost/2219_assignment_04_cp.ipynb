{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee26efec",
   "metadata": {},
   "source": [
    "# LCPB 21-22 exercise 4: XGBoost\n",
    "\n",
    "Alessandro Zanoli, Emerson Rodrigues Vero filho, Luca Giorgetti, Raffaele Gaudio\n",
    "\n",
    "#### TASK 1\n",
    "\n",
    "Consider the dataset generated for exercise 03 on convolutional neural networks (CNN), namely the samples of the stochastic time series with labels 0,1,2 depending on the eventual addition of another transient signal.\n",
    "\n",
    "a) Compare the accuracy of a CNN with that of an XGBoost model trained with the features extracted by tsfresh from same data, in the limit of small datasets. For instance, try values of N=20, 50, 100, 150, 200, 250, 300, 400, 500. In all cases show also the standard deviation of the accuracy, obtained from several independent training and test procedures on different datasets.\n",
    "\n",
    "b) For task a) we have seen during the lesson that XGBoost finds some features more relevant than others. Find the description of those features in the documentation and try to provide an explanation of why they are relevant for that problem.\n",
    "\n",
    "c) OPTIONAL: with the features extracted by tsfresh, train a standard (non-convolutional) feed forward neural network (FFNN) and compare the performances with those of XGBoost. Than keep only the most relevant features from XGBoost and train another FFNN with this smaller set. Is the new FFNN working better than the one trained with all features?\n",
    "\n",
    "#### TASK 2\n",
    "\n",
    "For the labeling of simple two dimensional data (as the one generated during the lesson), try different parameters (gamma, lambda, n_estimators, ...), aiming to find the simplest yet effective XGBoost model that keeps a good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f7b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.random as tf_r\n",
    "from scipy.signal import detrend # for CNN\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from tsfresh import extract_features\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "from keras import regularizers, initializers\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "np.random.seed(12345)\n",
    "tf_r.set_seed(12345) \n",
    "%run plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf7bcd",
   "metadata": {},
   "source": [
    "## Generate Data (1d time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a9016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the random step, using lambda construction\n",
    "# int() for cleaner look and for mimiking a detector with finite resolution\n",
    "jump = lambda drift, stdev: int(np.random.normal(drift,stdev))\n",
    "\n",
    "def pattern(i,z,a):\n",
    "    return int(a*np.sin((np.pi*i)/z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de9742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -5, 23, 3, -19, 84, 158, 167, 186, 229, 296, 351, 292, 310, 326, 398, 447, 352, 339, 427, 411, 390, 418, 585, 539, 516, 527, 547, 578, 583, 655, 625, 589, 476, 388, 350, 383, 325, 335, 287, 308, 196, 192, 120, 77, 17, 36, 59, 27, 48, 120, 128, 145, 149, 204, 275, 235, 163, 169, 211] 0\n",
      "[183, 231, 235, 242, 280, 327, 285, 288, 307, 400, 449, 468, 575, 634, 655, 661, 561, 431, 270, 110, 126, 133, 81, 126, 152, 207, 303, 259, 306, 305, 355, 369, 482, 482, 587, 593, 637, 647, 615, 649, 661, 588, 565, 568, 527, 508, 511, 570, 624, 600, 684, 663, 690, 741, 668, 622, 607, 623, 619, 657] 1\n",
      "[580, 623, 678, 663, 597, 579, 558, 521, 610, 643, 496, 417, 360, 369, 247, 190, 258, 256, 359, 489, 648, 783, 751, 706, 825, 746, 794, 774, 749, 796, 798, 793, 831, 835, 777, 810, 841, 801, 790, 777, 894, 865, 828, 836, 837, 826, 839, 855, 854, 851, 785, 799, 883, 811, 830, 807, 807, 804, 789, 732] 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pattern parameters: Z=nr of steps, A=amplitude\n",
    "Z=12\n",
    "A=500\n",
    "\n",
    "# number of data samples\n",
    "N=10000\n",
    "# size of each sample of the timeseries\n",
    "L=60\n",
    "# step parameters: introduce small positive bias \n",
    "DX = 50\n",
    "bias = 5\n",
    "\n",
    "y = [0] * N # list of N zeros\n",
    "x = [[0] * L for i in range(N)] # NxL matrix\n",
    "                                #\n",
    "for i in range(N):\n",
    "    if i>0:\n",
    "        x[i][0] = x[i-1][-1] + jump(bias,DX) #\n",
    "    \n",
    "    for j in range(1,L):\n",
    "        x[i][j] = x[i][j-1] + jump(bias,DX)\n",
    "        \n",
    "    y[i] = i%3 \n",
    "    ##y[i] = random.randint(0,2)\n",
    "    if y[i]>0:\n",
    "        j0 = np.random.randint(0,L-1-Z)\n",
    "        ###print(i,j0,j1)\n",
    "        sign = 3-2*y[i]\n",
    "        for j in range(Z):\n",
    "            x[i][j0+j] += sign*pattern(j,Z,A)\n",
    "            \n",
    "for i in range(min(3,N)):\n",
    "    print(x[i],y[i])\n",
    "    \n",
    "\n",
    "Show_data(x,L,\"original data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3ba97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_L60_Z12_A500_DX50_bias5_N10000.dat\n"
     ]
    }
   ],
   "source": [
    "#!mkdir DATA\n",
    "str0 = f'ts_L{L}_Z{Z}_A{A}_DX{DX}_bias{bias}_N{N}.dat'\n",
    "print(str0)\n",
    "\n",
    "fname='DATA/x_'+str0\n",
    "np.savetxt(fname,x,fmt=\"%d\")\n",
    "fname='DATA/y_'+str0\n",
    "np.savetxt(fname,y,fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ef8b4",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b245f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  10000\n"
     ]
    }
   ],
   "source": [
    "#use the dataset generated in the last exercise (we have to use the same data as in exercise 3 because we will compare the performances of CNN and Xgboost)\n",
    "\n",
    "str0 = 'ts_L60_Z12_A500_DX50_bias5_N10000.dat'\n",
    "fnamex='DATA/x_'+str0\n",
    "fnamey='DATA/y_'+str0\n",
    "\n",
    "x = np.loadtxt(fnamex, delimiter=\" \",dtype=float)\n",
    "N,L = len(x), len(x[0])\n",
    "\n",
    "# note: here it does not need to be converted to the 3-bit version, a label remains y[i]=0,1,2\n",
    "y = np.loadtxt(fnamey, dtype=int)\n",
    "n_class = 3    #  = len(np.unique(y))\n",
    "print('data: ',N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d1b56",
   "metadata": {},
   "source": [
    "## TSFRESH: extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa01933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per i blocchi a seguire dobbiamo aggiustare l'input (abbiamo una serie 2d)\n",
    "\n",
    "def get_df(x):\n",
    "    '''Build input dataframe for given data series\n",
    "    Input:\n",
    "    var = array of time series, (#samples,time,1)\n",
    "    Return:\n",
    "    df = dataframe ready for features extraction\n",
    "    '''\n",
    "    \n",
    "    #N = #samples, t = timesteps\n",
    "    N, t = x.shape[0], x.shape[1]\n",
    "    #build id columns\n",
    "    id_col = np.repeat(np.arange(N),t) \n",
    "    #build time columns\n",
    "    time_col = np.tile(np.arange(t),N) #genera n colonne di tempi \n",
    "    #build var column\n",
    "    x_col = x.flatten()\n",
    "      \n",
    "    #build dict for df\n",
    "    x_dict = {'id':id_col,'time':time_col,'value':x_col}\n",
    "        \n",
    "    #return dataframe\n",
    "    return pd.DataFrame(x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fed762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>9999</td>\n",
       "      <td>55</td>\n",
       "      <td>2977193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>9999</td>\n",
       "      <td>56</td>\n",
       "      <td>2977276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>9999</td>\n",
       "      <td>57</td>\n",
       "      <td>2977286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>9999</td>\n",
       "      <td>58</td>\n",
       "      <td>2977386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>9999</td>\n",
       "      <td>59</td>\n",
       "      <td>2977349.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  time      value\n",
       "0          0     0        0.0\n",
       "1          0     1       -5.0\n",
       "2          0     2       23.0\n",
       "3          0     3        3.0\n",
       "4          0     4      -19.0\n",
       "...      ...   ...        ...\n",
       "599995  9999    55  2977193.0\n",
       "599996  9999    56  2977276.0\n",
       "599997  9999    57  2977286.0\n",
       "599998  9999    58  2977386.0\n",
       "599999  9999    59  2977349.0\n",
       "\n",
       "[600000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=get_df(x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4526bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [05:17<00:00, 15.87s/it]\n"
     ]
    }
   ],
   "source": [
    "#extract features\n",
    "x_features = extract_features(\n",
    "                            df, #our dataframe\n",
    "                            column_id='id', #sample id, from 0 to N\n",
    "                            column_sort='time', #timestep, from 0 to t\n",
    "                            column_kind=None, #we have only one feature\n",
    "                            column_value='value', #value of input \n",
    "                            n_jobs=4) #number of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57475604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with NaN or inf\n",
    "x_features.replace([np.inf, -np.inf], np.nan)\n",
    "x_features = x_features.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924a6874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__variance_larger_than_standard_deviation</th>\n",
       "      <th>value__has_duplicate_max</th>\n",
       "      <th>value__has_duplicate_min</th>\n",
       "      <th>value__has_duplicate</th>\n",
       "      <th>value__sum_values</th>\n",
       "      <th>value__abs_energy</th>\n",
       "      <th>value__mean_abs_change</th>\n",
       "      <th>value__mean_change</th>\n",
       "      <th>value__mean_second_derivative_central</th>\n",
       "      <th>value__median</th>\n",
       "      <th>...</th>\n",
       "      <th>value__fourier_entropy__bins_2</th>\n",
       "      <th>value__fourier_entropy__bins_3</th>\n",
       "      <th>value__fourier_entropy__bins_5</th>\n",
       "      <th>value__fourier_entropy__bins_10</th>\n",
       "      <th>value__fourier_entropy__bins_100</th>\n",
       "      <th>value__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_7__tau_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16750.0</td>\n",
       "      <td>6.729150e+06</td>\n",
       "      <td>43.101695</td>\n",
       "      <td>3.576271</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>289.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239217</td>\n",
       "      <td>0.283936</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>0.980757</td>\n",
       "      <td>1.606551</td>\n",
       "      <td>2.560840</td>\n",
       "      <td>3.232518</td>\n",
       "      <td>3.608440</td>\n",
       "      <td>3.809279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27302.0</td>\n",
       "      <td>1.455619e+07</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>8.033898</td>\n",
       "      <td>-0.086207</td>\n",
       "      <td>509.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317937</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>1.107653</td>\n",
       "      <td>1.547018</td>\n",
       "      <td>2.436717</td>\n",
       "      <td>3.108691</td>\n",
       "      <td>3.462655</td>\n",
       "      <td>3.659720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41650.0</td>\n",
       "      <td>3.090479e+07</td>\n",
       "      <td>45.491525</td>\n",
       "      <td>2.576271</td>\n",
       "      <td>-0.862069</td>\n",
       "      <td>784.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142506</td>\n",
       "      <td>0.142506</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>1.107653</td>\n",
       "      <td>1.745508</td>\n",
       "      <td>2.930054</td>\n",
       "      <td>3.743700</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>3.988984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37428.0</td>\n",
       "      <td>2.393510e+07</td>\n",
       "      <td>44.372881</td>\n",
       "      <td>-2.169492</td>\n",
       "      <td>1.008621</td>\n",
       "      <td>631.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317937</td>\n",
       "      <td>0.473981</td>\n",
       "      <td>0.687083</td>\n",
       "      <td>1.320351</td>\n",
       "      <td>2.757282</td>\n",
       "      <td>1.695334</td>\n",
       "      <td>2.879917</td>\n",
       "      <td>3.584589</td>\n",
       "      <td>3.871793</td>\n",
       "      <td>3.937640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58260.0</td>\n",
       "      <td>6.072359e+07</td>\n",
       "      <td>54.593220</td>\n",
       "      <td>10.728814</td>\n",
       "      <td>-0.422414</td>\n",
       "      <td>909.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239217</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>0.656671</td>\n",
       "      <td>0.838120</td>\n",
       "      <td>1.668815</td>\n",
       "      <td>2.785780</td>\n",
       "      <td>3.277698</td>\n",
       "      <td>3.575507</td>\n",
       "      <td>3.773917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178577898.0</td>\n",
       "      <td>5.315011e+14</td>\n",
       "      <td>44.898305</td>\n",
       "      <td>3.813559</td>\n",
       "      <td>-0.232759</td>\n",
       "      <td>2976394.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239217</td>\n",
       "      <td>0.283936</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>0.563420</td>\n",
       "      <td>1.134027</td>\n",
       "      <td>1.588719</td>\n",
       "      <td>2.476201</td>\n",
       "      <td>3.245121</td>\n",
       "      <td>3.619739</td>\n",
       "      <td>3.789900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178600157.0</td>\n",
       "      <td>5.316336e+14</td>\n",
       "      <td>40.288136</td>\n",
       "      <td>10.694915</td>\n",
       "      <td>-0.758621</td>\n",
       "      <td>2976629.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142506</td>\n",
       "      <td>0.142506</td>\n",
       "      <td>0.283936</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>1.237411</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>2.603521</td>\n",
       "      <td>3.355240</td>\n",
       "      <td>3.786663</td>\n",
       "      <td>3.876606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178618515.0</td>\n",
       "      <td>5.317429e+14</td>\n",
       "      <td>48.915254</td>\n",
       "      <td>-1.423729</td>\n",
       "      <td>-0.422414</td>\n",
       "      <td>2976910.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239217</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>0.656671</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>1.657902</td>\n",
       "      <td>2.624445</td>\n",
       "      <td>3.267602</td>\n",
       "      <td>3.634172</td>\n",
       "      <td>3.876606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178611894.0</td>\n",
       "      <td>5.317035e+14</td>\n",
       "      <td>57.677966</td>\n",
       "      <td>-0.762712</td>\n",
       "      <td>0.577586</td>\n",
       "      <td>2976930.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384543</td>\n",
       "      <td>0.457102</td>\n",
       "      <td>0.656671</td>\n",
       "      <td>0.838120</td>\n",
       "      <td>0.973558</td>\n",
       "      <td>1.643572</td>\n",
       "      <td>2.582843</td>\n",
       "      <td>3.294830</td>\n",
       "      <td>3.639092</td>\n",
       "      <td>3.757935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178619969.0</td>\n",
       "      <td>5.317516e+14</td>\n",
       "      <td>41.084746</td>\n",
       "      <td>6.711864</td>\n",
       "      <td>-0.612069</td>\n",
       "      <td>2976995.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239217</td>\n",
       "      <td>0.283936</td>\n",
       "      <td>0.283936</td>\n",
       "      <td>0.659243</td>\n",
       "      <td>1.876251</td>\n",
       "      <td>1.707294</td>\n",
       "      <td>2.760877</td>\n",
       "      <td>3.492872</td>\n",
       "      <td>3.871793</td>\n",
       "      <td>3.988984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      value__variance_larger_than_standard_deviation  \\\n",
       "0                                                1.0   \n",
       "1                                                1.0   \n",
       "2                                                1.0   \n",
       "3                                                1.0   \n",
       "4                                                1.0   \n",
       "...                                              ...   \n",
       "9995                                             1.0   \n",
       "9996                                             1.0   \n",
       "9997                                             1.0   \n",
       "9998                                             1.0   \n",
       "9999                                             1.0   \n",
       "\n",
       "      value__has_duplicate_max  value__has_duplicate_min  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "9995                       1.0                       0.0   \n",
       "9996                       0.0                       0.0   \n",
       "9997                       0.0                       0.0   \n",
       "9998                       0.0                       0.0   \n",
       "9999                       0.0                       0.0   \n",
       "\n",
       "      value__has_duplicate  value__sum_values  value__abs_energy  \\\n",
       "0                      1.0            16750.0       6.729150e+06   \n",
       "1                      1.0            27302.0       1.455619e+07   \n",
       "2                      1.0            41650.0       3.090479e+07   \n",
       "3                      1.0            37428.0       2.393510e+07   \n",
       "4                      1.0            58260.0       6.072359e+07   \n",
       "...                    ...                ...                ...   \n",
       "9995                   1.0        178577898.0       5.315011e+14   \n",
       "9996                   1.0        178600157.0       5.316336e+14   \n",
       "9997                   1.0        178618515.0       5.317429e+14   \n",
       "9998                   1.0        178611894.0       5.317035e+14   \n",
       "9999                   1.0        178619969.0       5.317516e+14   \n",
       "\n",
       "      value__mean_abs_change  value__mean_change  \\\n",
       "0                  43.101695            3.576271   \n",
       "1                  44.000000            8.033898   \n",
       "2                  45.491525            2.576271   \n",
       "3                  44.372881           -2.169492   \n",
       "4                  54.593220           10.728814   \n",
       "...                      ...                 ...   \n",
       "9995               44.898305            3.813559   \n",
       "9996               40.288136           10.694915   \n",
       "9997               48.915254           -1.423729   \n",
       "9998               57.677966           -0.762712   \n",
       "9999               41.084746            6.711864   \n",
       "\n",
       "      value__mean_second_derivative_central  value__median  ...  \\\n",
       "0                                  0.405172          289.5  ...   \n",
       "1                                 -0.086207          509.5  ...   \n",
       "2                                 -0.862069          784.0  ...   \n",
       "3                                  1.008621          631.0  ...   \n",
       "4                                 -0.422414          909.0  ...   \n",
       "...                                     ...            ...  ...   \n",
       "9995                              -0.232759      2976394.0  ...   \n",
       "9996                              -0.758621      2976629.0  ...   \n",
       "9997                              -0.422414      2976910.5  ...   \n",
       "9998                               0.577586      2976930.0  ...   \n",
       "9999                              -0.612069      2976995.5  ...   \n",
       "\n",
       "      value__fourier_entropy__bins_2  value__fourier_entropy__bins_3  \\\n",
       "0                           0.239217                        0.283936   \n",
       "1                           0.317937                        0.379535   \n",
       "2                           0.142506                        0.142506   \n",
       "3                           0.317937                        0.473981   \n",
       "4                           0.239217                        0.379535   \n",
       "...                              ...                             ...   \n",
       "9995                        0.239217                        0.283936   \n",
       "9996                        0.142506                        0.142506   \n",
       "9997                        0.239217                        0.379535   \n",
       "9998                        0.384543                        0.457102   \n",
       "9999                        0.239217                        0.283936   \n",
       "\n",
       "      value__fourier_entropy__bins_5  value__fourier_entropy__bins_10  \\\n",
       "0                           0.424254                         0.424254   \n",
       "1                           0.379535                         0.518700   \n",
       "2                           0.379535                         0.424254   \n",
       "3                           0.687083                         1.320351   \n",
       "4                           0.424254                         0.656671   \n",
       "...                              ...                              ...   \n",
       "9995                        0.424254                         0.563420   \n",
       "9996                        0.283936                         0.424254   \n",
       "9997                        0.424254                         0.656671   \n",
       "9998                        0.656671                         0.838120   \n",
       "9999                        0.283936                         0.659243   \n",
       "\n",
       "      value__fourier_entropy__bins_100  \\\n",
       "0                             0.980757   \n",
       "1                             1.107653   \n",
       "2                             1.107653   \n",
       "3                             2.757282   \n",
       "4                             0.838120   \n",
       "...                                ...   \n",
       "9995                          1.134027   \n",
       "9996                          1.237411   \n",
       "9997                          0.928839   \n",
       "9998                          0.973558   \n",
       "9999                          1.876251   \n",
       "\n",
       "      value__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                           1.606551   \n",
       "1                                           1.547018   \n",
       "2                                           1.745508   \n",
       "3                                           1.695334   \n",
       "4                                           1.668815   \n",
       "...                                              ...   \n",
       "9995                                        1.588719   \n",
       "9996                                        1.655861   \n",
       "9997                                        1.657902   \n",
       "9998                                        1.643572   \n",
       "9999                                        1.707294   \n",
       "\n",
       "      value__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                           2.560840   \n",
       "1                                           2.436717   \n",
       "2                                           2.930054   \n",
       "3                                           2.879917   \n",
       "4                                           2.785780   \n",
       "...                                              ...   \n",
       "9995                                        2.476201   \n",
       "9996                                        2.603521   \n",
       "9997                                        2.624445   \n",
       "9998                                        2.582843   \n",
       "9999                                        2.760877   \n",
       "\n",
       "      value__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                           3.232518   \n",
       "1                                           3.108691   \n",
       "2                                           3.743700   \n",
       "3                                           3.584589   \n",
       "4                                           3.277698   \n",
       "...                                              ...   \n",
       "9995                                        3.245121   \n",
       "9996                                        3.355240   \n",
       "9997                                        3.267602   \n",
       "9998                                        3.294830   \n",
       "9999                                        3.492872   \n",
       "\n",
       "      value__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                           3.608440   \n",
       "1                                           3.462655   \n",
       "2                                           4.007333   \n",
       "3                                           3.871793   \n",
       "4                                           3.575507   \n",
       "...                                              ...   \n",
       "9995                                        3.619739   \n",
       "9996                                        3.786663   \n",
       "9997                                        3.634172   \n",
       "9998                                        3.639092   \n",
       "9999                                        3.871793   \n",
       "\n",
       "      value__permutation_entropy__dimension_7__tau_1  \n",
       "0                                           3.809279  \n",
       "1                                           3.659720  \n",
       "2                                           3.988984  \n",
       "3                                           3.937640  \n",
       "4                                           3.773917  \n",
       "...                                              ...  \n",
       "9995                                        3.789900  \n",
       "9996                                        3.876606  \n",
       "9997                                        3.876606  \n",
       "9998                                        3.757935  \n",
       "9999                                        3.988984  \n",
       "\n",
       "[10000 rows x 497 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at clean x_features\n",
    "x_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07027fb",
   "metadata": {},
   "source": [
    "### Split train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a522d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label preparation for CNN\n",
    "y_CNN = np.zeros((len(y),3))\n",
    "for i,iy in enumerate(y):\n",
    "    y_CNN[i][iy]=1\n",
    "\n",
    "#shuffling data\n",
    "perm=np.random.permutation(x_features.shape[0])\n",
    "\n",
    "x_features=x_features.iloc[perm]\n",
    "y = y[perm]\n",
    "x = x[perm]\n",
    "y_CNN = y_CNN[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63b1c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_train= 8000   N_val= 2000   n_class= 3\n"
     ]
    }
   ],
   "source": [
    "#split data into training and validation\n",
    "\n",
    "perc_train=0.8\n",
    "N_train = int(perc_train*N)\n",
    "\n",
    "if True:\n",
    "    #rescaling x_features for XGB\n",
    "    x_features -= np.mean(x_features,axis=0)\n",
    "    x_features /= np.std(x_features,axis=0)\n",
    "\n",
    "    # detrending and rescaling x for CNN\n",
    "    for i in range(len(x)):\n",
    "        x[i] = detrend(x[i])\n",
    "    x /= np.var(x)\n",
    "\n",
    "x = x.reshape((*x.shape,1)) # reshape for CNN\n",
    "\n",
    "x_XGB_train = x_features[:N_train]\n",
    "x_CNN_train = x[:N_train]\n",
    "x_XGB_val = x_features[N_train:]\n",
    "x_CNN_val = x[N_train:]\n",
    "\n",
    "    \n",
    "y_CNN_train = y_CNN[:N_train]\n",
    "y_CNN_val = y_CNN[N_train:]\n",
    "y_XGB_train = y[:N_train]\n",
    "y_XGB_val = y[N_train:]\n",
    "\n",
    "N_val = N-N_train\n",
    "print('N_train=',N_train,'  N_val=',N_val,'  n_class=',n_class)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece035b",
   "metadata": {},
   "source": [
    "# Build models\n",
    "\n",
    "## XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d06337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters for xgboost\n",
    "params = {'max_depth':6,'min_child_weight':1,\\\n",
    "          'learning_rate':0.3,'use_label_encoder':False}\n",
    "\n",
    "#build model with given params\n",
    "model_XGB = XGBClassifier(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380148de",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f1f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = regularizers.l2(0.1) \n",
    "ini = initializers.RandomNormal(mean=1.0,stddev=0.05,seed=12345)\n",
    "M = 15 # lenght of kernel: its shape will be M\n",
    "       # larger than Z=12 which is the size of the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813d16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model with no input shape\n",
    "\n",
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv1D(filters=3,kernel_size=M,kernel_initializer=ini,kernel_regularizer=reg,input_shape=(L,1),use_bias=False))\n",
    "model_CNN.add(MaxPooling1D(pool_size=2))\n",
    "model_CNN.add(Conv1D(filters=2,kernel_size=int(M/2)))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(12,activation='sigmoid')) # just a 12 neurons layer\n",
    "model_CNN.add(Dense(n_class,activation='softmax'))\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1.,decay_steps=1000,decay_rate=0.9)\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# compile the model\n",
    "model_CNN.compile(loss=keras.losses.categorical_crossentropy,optimizer=opt,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e0d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MODEL SUMMARY ------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 46, 3)             45        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 23, 3)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 17, 2)             44        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 34)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                420       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 39        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 548\n",
      "Trainable params: 548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('----- MODEL SUMMARY ------')\n",
    "print(model_CNN.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01217811",
   "metadata": {},
   "source": [
    "## XGBoos VS CNN on small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e77d07e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 16 subsets of size 20\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:52:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 5.5668 - accuracy: 0.3500\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:52:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 5.9074 - accuracy: 0.2000\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:52:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 5.8890 - accuracy: 0.1000\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 5.8748 - accuracy: 0.2500\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 5.5888 - accuracy: 0.5000\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:52:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 5.5328 - accuracy: 0.4000\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:52:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 5.6154 - accuracy: 0.4000\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:52:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 5.6771 - accuracy: 0.4500\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:52:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 5.7369 - accuracy: 0.2000\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 5.6987 - accuracy: 0.2500\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 5.5935 - accuracy: 0.4500\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 5.6620 - accuracy: 0.3500\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 6.0779 - accuracy: 0.2500\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:52:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 5.8060 - accuracy: 0.4000\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:52:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 5.5958 - accuracy: 0.5000\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:52:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 5.7978 - accuracy: 0.3500\n",
      "Training 16 subsets of size 50\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:52:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6795 - accuracy: 0.4200\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:52:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6784 - accuracy: 0.3800\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:52:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6364 - accuracy: 0.3800\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:52:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7987 - accuracy: 0.2600\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:52:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8161 - accuracy: 0.3600\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:52:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7939 - accuracy: 0.4200\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:52:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.9484 - accuracy: 0.3400\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:52:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6277 - accuracy: 0.4200\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:52:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.5735 - accuracy: 0.4200\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:52:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6631 - accuracy: 0.3200\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:52:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 1s 2ms/step - loss: 5.6997 - accuracy: 0.3400\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:52:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6525 - accuracy: 0.3400\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:52:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8284 - accuracy: 0.3000\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:52:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7793 - accuracy: 0.3400\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:52:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6445 - accuracy: 0.5000\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:52:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4568 - accuracy: 0.4200\n",
      "Training 16 subsets of size 100\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:52:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.6733 - accuracy: 0.2600\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:52:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.7175 - accuracy: 0.3400\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:52:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.7298 - accuracy: 0.2800\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:52:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.7481 - accuracy: 0.3200\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:52:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.7757 - accuracy: 0.3400\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:52:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.7261 - accuracy: 0.2900\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:52:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.8442 - accuracy: 0.3200\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:52:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.7458 - accuracy: 0.2300\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:52:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.6251 - accuracy: 0.3700\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:52:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.5688 - accuracy: 0.3600\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:53:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.7072 - accuracy: 0.2800\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:53:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.5483 - accuracy: 0.3500\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:53:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2224 - accuracy: 0.2700\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:53:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.5935 - accuracy: 0.3300\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:53:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.5717 - accuracy: 0.3600\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:53:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.6843 - accuracy: 0.3000\n",
      "Training 16 subsets of size 150\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:53:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8083 - accuracy: 0.3733\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:53:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8954 - accuracy: 0.3000\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:53:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.1636 - accuracy: 0.3000\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:53:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.7273 - accuracy: 0.3800\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:53:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6512 - accuracy: 0.3933\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:53:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 1s 3ms/step - loss: 5.7202 - accuracy: 0.3667\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:53:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5540 - accuracy: 0.3333\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:53:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.7821 - accuracy: 0.2867\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:53:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.6716 - accuracy: 0.2733\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:53:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.6217 - accuracy: 0.3667\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:53:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.5907 - accuracy: 0.4000\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:53:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.6323 - accuracy: 0.3067\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:53:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 5.5619 - accuracy: 0.3133\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.6749 - accuracy: 0.3067\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:53:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7134 - accuracy: 0.2733\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:53:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.8762 - accuracy: 0.3400\n",
      "Training 16 subsets of size 200\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:53:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5864 - accuracy: 0.3450\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:53:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5835 - accuracy: 0.3500\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:53:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6781 - accuracy: 0.3150\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:53:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8161 - accuracy: 0.2750\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:53:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 5.4953 - accuracy: 0.3300\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:53:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.6230 - accuracy: 0.3800\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:53:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5668 - accuracy: 0.4100\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:53:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7683 - accuracy: 0.3350\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:53:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6109 - accuracy: 0.4200\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:53:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8177 - accuracy: 0.3050\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:53:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6245 - accuracy: 0.3050\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:53:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.7293 - accuracy: 0.2800\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:53:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6237 - accuracy: 0.3550\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:53:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6699 - accuracy: 0.3700\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:53:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.5180 - accuracy: 0.3400\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:53:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5847 - accuracy: 0.3150\n",
      "Training 16 subsets of size 250\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:53:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.4331 - accuracy: 0.3600\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:53:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5022 - accuracy: 0.3360\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:53:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.9222 - accuracy: 0.3280\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:53:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5124 - accuracy: 0.3040\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:53:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5571 - accuracy: 0.3720\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:53:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5480 - accuracy: 0.3240\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:53:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.4242 - accuracy: 0.4000\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:53:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.8279 - accuracy: 0.3520\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:53:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.5103 - accuracy: 0.4000\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:53:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5767 - accuracy: 0.3240\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:53:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.6964 - accuracy: 0.3120\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:53:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5346 - accuracy: 0.3480\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:53:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.5011 - accuracy: 0.3360\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:53:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.6330 - accuracy: 0.3200\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:53:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.6215 - accuracy: 0.3760\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:53:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.6065 - accuracy: 0.2840\n",
      "Training 16 subsets of size 300\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:53:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6080 - accuracy: 0.3167\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:53:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7394 - accuracy: 0.3233\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:53:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4276 - accuracy: 0.3733\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:53:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5037 - accuracy: 0.3033\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:53:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4237 - accuracy: 0.3800\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:53:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.4702 - accuracy: 0.3967\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:53:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4922 - accuracy: 0.3700\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:53:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5934 - accuracy: 0.3433\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:53:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.4164 - accuracy: 0.3133\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:54:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5666 - accuracy: 0.3467\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:54:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.5466 - accuracy: 0.3600\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:54:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6558 - accuracy: 0.3733\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:54:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.8229 - accuracy: 0.2900\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:54:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4541 - accuracy: 0.3033\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:54:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5287 - accuracy: 0.3600\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:54:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.5536 - accuracy: 0.3833\n",
      "Training 16 subsets of size 400\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:54:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5127 - accuracy: 0.2900\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:54:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3793 - accuracy: 0.3400\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:54:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.4204 - accuracy: 0.3725\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:54:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4190 - accuracy: 0.3625\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:54:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5369 - accuracy: 0.2900\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:54:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.7920 - accuracy: 0.3300\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:54:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4498 - accuracy: 0.3025\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:54:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4781 - accuracy: 0.3525\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:54:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.7905 - accuracy: 0.2925\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:54:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.7644 - accuracy: 0.3025\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:54:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5215 - accuracy: 0.3350\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:54:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4247 - accuracy: 0.3650\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:54:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5418 - accuracy: 0.3550\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:54:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.7298 - accuracy: 0.3475\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:54:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3827 - accuracy: 0.3250\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:54:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5509 - accuracy: 0.3175\n",
      "Training 16 subsets of size 500\n",
      "---------------------\n",
      "\n",
      "Training subset number 0 ...\n",
      "Training XGBoost...\n",
      "[19:54:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3635 - accuracy: 0.3580\n",
      "Training subset number 1 ...\n",
      "Training XGBoost...\n",
      "[19:54:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4342 - accuracy: 0.3460\n",
      "Training subset number 2 ...\n",
      "Training XGBoost...\n",
      "[19:54:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5090 - accuracy: 0.3320\n",
      "Training subset number 3 ...\n",
      "Training XGBoost...\n",
      "[19:54:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4733 - accuracy: 0.3760\n",
      "Training subset number 4 ...\n",
      "Training XGBoost...\n",
      "[19:54:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4463 - accuracy: 0.3280\n",
      "Training subset number 5 ...\n",
      "Training XGBoost...\n",
      "[19:54:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4007 - accuracy: 0.3940\n",
      "Training subset number 6 ...\n",
      "Training XGBoost...\n",
      "[19:54:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4837 - accuracy: 0.3200\n",
      "Training subset number 7 ...\n",
      "Training XGBoost...\n",
      "[19:54:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4727 - accuracy: 0.3280\n",
      "Training subset number 8 ...\n",
      "Training XGBoost...\n",
      "[19:54:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.4880 - accuracy: 0.3300\n",
      "Training subset number 9 ...\n",
      "Training XGBoost...\n",
      "[19:54:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6130 - accuracy: 0.3340\n",
      "Training subset number 10 ...\n",
      "Training XGBoost...\n",
      "[19:54:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4775 - accuracy: 0.3200\n",
      "Training subset number 11 ...\n",
      "Training XGBoost...\n",
      "[19:54:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3705 - accuracy: 0.3600\n",
      "Training subset number 12 ...\n",
      "Training XGBoost...\n",
      "[19:54:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2132 - accuracy: 0.3800\n",
      "Training subset number 13 ...\n",
      "Training XGBoost...\n",
      "[19:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3008 - accuracy: 0.3300\n",
      "Training subset number 14 ...\n",
      "Training XGBoost...\n",
      "[19:54:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4233 - accuracy: 0.3340\n",
      "Training subset number 15 ...\n",
      "Training XGBoost...\n",
      "[19:54:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training CNN...\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2153 - accuracy: 0.3820\n"
     ]
    }
   ],
   "source": [
    "# ENTER THE MEGACELLA OF DEATH\n",
    "\n",
    "Ns_sub = [20,50,100,150,200,250,300,400,500]\n",
    "bag_size = 16 # = 8000/500\n",
    "verbose = True\n",
    "\n",
    "# dictionary to store accuracy for xgb and cnn model, both for training set and validation set\n",
    "accuracies = {\"xgb\" : {\"train\": np.zeros((len(Ns_sub),16)),\n",
    "                        \"val\": np.zeros((len(Ns_sub),16))},\n",
    "            \"cnn\" : {\"train\" : np.zeros((len(Ns_sub),16)),\n",
    "                    \"val\" : np.zeros((len(Ns_sub),16))\n",
    "            }\n",
    "}\n",
    "\n",
    "for i_n,N_sub in enumerate(Ns_sub):\n",
    "    \n",
    "    if verbose: print(\"Training {} subsets of size {}\\n---------------------\\n\".format(bag_size,N_sub))\n",
    "\n",
    "    for i in range(bag_size):\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"Training subset number {} ...\".format(i))\n",
    "            print(\"Training XGBoost...\")\n",
    "\n",
    "        # XGBoost\n",
    "        model_XGB.fit(x_XGB_train.iloc[N_sub*i:N_sub*(i+1)].values,y_XGB_train[N_sub*i:N_sub*(i+1)])\n",
    "        \n",
    "        y_xgb_pred_train = model_XGB.predict(x_XGB_train.iloc[N_sub*i:N_sub*(i+1)].values)\n",
    "        y_xgb_pred_val = model_XGB.predict(x_XGB_val.values)\n",
    "\n",
    "        accuracies[\"xgb\"][\"train\"][i_n][i] = accuracy_score(y_XGB_train[N_sub*i:N_sub*(i+1)],y_xgb_pred_train)\n",
    "        accuracies[\"xgb\"][\"val\"][i_n][i] = accuracy_score(y_XGB_val,y_xgb_pred_val)\n",
    "\n",
    "        if verbose: print(\"Training CNN...\")\n",
    "        # CNN\n",
    "\n",
    "        model_temp_CNN = keras.models.clone_model(model_CNN) # clone anew\n",
    "        model_temp_CNN.compile(loss=keras.losses.categorical_crossentropy,optimizer=opt,metrics=['accuracy'])\n",
    "        model_temp_CNN.fit(x_CNN_train[N_sub*i:N_sub*(i+1)],y_CNN_train[N_sub*i:N_sub*(i+1)])\n",
    "\n",
    "        y_cnn_pred_train = np.argmax(model_temp_CNN.predict(x_CNN_train[N_sub*i:N_sub*(i+1)]),axis=-1)\n",
    "        y_cnn_pred_val = np.argmax(model_temp_CNN.predict(x_CNN_val),axis=-1)\n",
    "\n",
    "\n",
    "        accuracies[\"cnn\"][\"train\"][i_n][i] = accuracy_score(np.argmax(y_CNN_train[N_sub*i:N_sub*(i+1)],axis=-1),y_cnn_pred_train)\n",
    "        accuracies[\"cnn\"][\"val\"][i_n][i] = accuracy_score(np.argmax(y_CNN_val,axis=-1),y_cnn_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa140dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies['xgb']['train'] # (9,16)\n",
    "                            # np.mean(axis=1)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=[16,6])\n",
    "# accuracy of train set\n",
    "axs[0].set_title(\"Train Accuracy\")\n",
    "axs[0].errorbar(Ns_sub,np.mean(accuracies['xgb']['train'],axis=1),yerr=np.std(accuracies['xgb']['train'],axis=1),label='XGBoost',linestyle='--')\n",
    "axs[0].errorbar(Ns_sub,np.mean(accuracies['cnn']['train'],axis=1),yerr=np.std(accuracies['cnn']['train'],axis=1),label='CNN',linestyle='--')\n",
    "#accuracy of test set\n",
    "axs[1].set_title(\"Validation Accuracy\")\n",
    "axs[1].errorbar(Ns_sub,np.mean(accuracies['xgb']['val'],axis=1),yerr=np.std(accuracies['xgb']['val'],axis=1),label='XGBoost',linestyle='--')\n",
    "axs[1].errorbar(Ns_sub,np.mean(accuracies['cnn']['val'],axis=1),yerr=np.std(accuracies['cnn']['val'],axis=1),label='CNN',linestyle='--')\n",
    "\n",
    "for ax in axs: ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190706c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
